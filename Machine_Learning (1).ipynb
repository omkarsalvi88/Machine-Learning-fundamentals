{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Questions\n",
        "\n",
        "1. What is a parameter?\n",
        "   - A parameter is an internal variable in a machine learning model that is learned from the training data. Examples include weights and biases in neural networks or coefficients in linear regression. Parameters help the model make predictions.\n",
        "\n",
        "\n",
        "2. What is correlation?\n",
        "   - Correlation measures the strength and direction of a linear relationship between two variables. Its value ranges from –1 to +1. A positive value means both variables increase together, while a negative value means one increases as the other decreases.\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "   - A negative correlation means that as one variable increases, the other decreases. The correlation coefficient lies between 0 and –1. Example: As outdoor temperature goes up, heater usage goes down\n",
        "\n",
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "   - Machine Learning (ML) is a field of AI where systems learn from data to make predictions or decisions without being explicitly programmed.Main components: 1)Data 2)Model 3)Training 4)Evaluation 5)Prediction\n",
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "   - The loss value shows how far the model’s predictions are from the actual values. A lower loss means a better performing model, while a high loss indicates poor performance.\n",
        "\n",
        "6. What are continuous and categorical variables?\n",
        "   - 1)Continuous variables: Numeric values with infinite possibilities (e.g., height, weight, temperature).\n",
        "   2)Categorical variables: Values that fall into categories (e.g., gender, color, city).\n",
        "\n",
        "7. How do we handle categorical variables in Machine Learning?\n",
        "   - Common techniques:\n",
        "   1)Label Encoding\n",
        "   2)One-Hot Encoding\n",
        "   3)Ordinal Encoding\n",
        "   4)Frequency Encoding\n",
        "\n",
        "8. What do you mean by training and testing a dataset?\n",
        "   - 1)Training set: Data used to train the model.\n",
        "  2)Testing set: Data used to evaluate model performance on unseen data.\n",
        "\n",
        "9. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a Scikit-learn module used for data preprocessing. It provides functions like scaling, normalization, encoding, etc.\n",
        "\n",
        "10. What is a Test set?\n",
        "    - The test set is a portion of the dataset used to evaluate the trained model and check its performance on unseen data.\n",
        "\n",
        "11. How do we split data for model fitting (training and testing) in Python?\n",
        "    - We use train_test_split from sklearn.model_selection:\n"
      ],
      "metadata": {
        "id": "_by-ZYvgmWWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "ko81dla7ofhR",
        "outputId": "20832e93-0e82-4df1-8b43-3d77a7ec9185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3645625029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How do you approach a Machine Learning problem?\n",
        "    - 1)Define the problem\n",
        "    2)Collect and clean data\n",
        "    3) Perform EDA\n",
        "    4)Feature engineering\n",
        "    5)Choose and train a model\n",
        "    6)Evaluate and optimize\n",
        "    7) Deploy the solution\n",
        "\n",
        "\n",
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "    - EDA (Exploratory Data Analysis) helps: 1) Understand data distribution\n",
        "    2)Detect outliers and missing values\n",
        "    3)Find feature relationships\n",
        "    4)Guide preprocessing steps\n",
        "    \n",
        "\n",
        "14. What is correlation?\n",
        "    - Correlation measures how strongly and in what direction two variables are related. It ranges from –1 (perfect negative) to +1 (perfect positive).\n",
        "\n",
        "\n",
        "15. What does negative correlation mean?\n",
        "    - Negative correlation means when one variable increases, the other decreases. Example: Increase in rainfall decreases the number of sunny days.\n",
        "\n",
        "\n",
        "16. How can you find correlation between variables in Python?\n",
        "    - An optimizer is an algorithm that adjusts the internal parameters (like weights and biases) of a machine learning or deep learning model in order to minimize the loss function and improve performance. In simple terms, an optimizer helps the model learn by finding the best possible parameters that reduce prediction errors. There are different types of optimizers used in machine learning. Gradient Descent is the most basic one; it updates weights in the opposite direction of the loss function’s gradient. Stochastic Gradient Descent (SGD) improves this by updating weights for each training sample or mini-batch, making learning faster but noisier. Momentum adds a term that helps the optimizer keep moving in the right direction even if gradients fluctuate. Adam (Adaptive Moment Estimation) combines the benefits of Momentum and RMSProp by adapting the learning rate for each parameter automatically and is one of the most widely used optimizers today. For example, in TensorFlow, we can use Adam with optimizer = Adam(learning_rate=0.001) to train a neural network efficiently.\n",
        "\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "    - sklearn.linear_model is a module in the scikit-learn library that provides various linear models for both regression and classification tasks. Linear models are those that assume a linear relationship between input features (X) and the target variable (y). This module includes algorithms like LinearRegression for predicting continuous values, LogisticRegression for binary or multiclass classification, and Ridge or Lasso regression which apply regularization to prevent overfitting. For instance, using LinearRegression() from this module allows us to train a model that predicts outcomes based on a straight-line relationship between features and the target.\n",
        "\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "    - The model.fit() function in scikit-learn (and most machine learning frameworks) is used to train the model on a given dataset. It takes the input data X (the features) and the output data y (the target variable) as arguments. During this process, the model learns the underlying patterns in the training data by adjusting its parameters to minimize the error between predictions and actual values. For example, in linear regression, fit() calculates the best-fit line that minimizes the sum of squared errors. The basic syntax is model.fit(X_train, y_train), where X_train and y_train represent the training portion of the dataset.\n",
        "\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "    - The model.predict() function is used after a model has been trained to generate predictions for new, unseen data. It takes the input features (usually called X_test) as an argument and outputs the model’s predicted values for the target variable. In a regression model, it returns continuous numerical predictions, while in a classification model, it predicts the class labels. For example, after training a linear regression model using model.fit(X_train, y_train), we can make predictions on new data with y_pred = model.predict(X_test).\n",
        "\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "    - In machine learning, variables (or features) are broadly divided into continuous and categorical types. Continuous variables are numeric values that can take any value within a range and can be measured on a continuous scale, such as height, weight, temperature, or income. On the other hand, categorical variables represent distinct categories or groups that describe qualitative characteristics, such as gender (male/female), color (red/blue/green), or city names. Continuous variables are usually used in regression problems, while categorical variables are often used in classification problems and require encoding before being used in numerical models.\n",
        "\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "    - Feature scaling is the process of transforming data so that all features have a similar scale or range. This step is important because many machine learning algorithms, such as K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Gradient Descent-based models, perform better when numerical features are on a comparable scale. Without scaling, features with large values (like income in thousands) may dominate those with smaller values (like age). Scaling helps models converge faster and improves accuracy. Common scaling methods include Standardization, which converts data to have zero mean and unit variance, and Normalization, which rescales values between 0 and 1.\n",
        "\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "    - In Python, feature scaling is most commonly performed using tools from the sklearn.preprocessing module. The StandardScaler is used for standardization, which transforms data so that it has a mean of 0 and a standard deviation of 1. Another popular method is the MinMaxScaler, which scales features to a fixed range, typically between 0 and 1.\n",
        "\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "    - sklearn.preprocessing is a module in scikit-learn that provides various tools for transforming raw data into a suitable format for machine learning models. It includes functions for feature scaling, encoding categorical variables, handling missing values, and normalizing data. Common classes include StandardScaler for standardization, MinMaxScaler for normalization, LabelEncoder for converting categorical labels into integers, and OneHotEncoder for creating dummy variables. Preprocessing ensures that all input features are numeric, well-scaled, and ready for model training.\n",
        "\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "    - To evaluate model performance fairly, we split our dataset into two parts — a training set for learning and a testing set for validation. In Python, this is commonly done using train_test_split() from sklearn.model_selection. The function randomly divides data into training and testing subsets, typically with 80% for training and 20% for testing\n",
        "\n",
        "\n",
        "25. Explain data encoding?\n",
        "    - Data encoding is the process of converting categorical (non-numeric) variables into numerical form so that machine learning models can interpret them. Since most algorithms can only process numerical input, encoding transforms text-based categories into numbers. Two main types of encoding are Label Encoding and One-Hot Encoding. Label Encoding assigns a unique integer to each category (e.g., Red = 0, Blue = 1, Green = 2), while One-Hot Encoding creates separate binary columns for each category (e.g., Red → [1,0,0], Blue → [0,1,0]). Scikit-learn provides built-in encoders such as LabelEncoder() and OneHotEncoder() to perform this transformation efficiently.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UeMPVkI7om5B"
      }
    }
  ]
}